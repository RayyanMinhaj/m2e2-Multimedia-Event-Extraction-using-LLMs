{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8dbbe6",
   "metadata": {},
   "source": [
    "# Reproducing M2E2 using a prompt-based LLM\n",
    "DFKI | Rayyan M."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2736b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d58748a",
   "metadata": {},
   "source": [
    "### Defining schema/ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b573b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event obj : argument roles from M2E2 dataset paper\n",
    "\n",
    "event_arg = {\n",
    "    \"life.die\":[\"agent\", \"victim\", \"instrument\", \"place\"],\n",
    "    \"movement.transport\":[\"destination\", \"origin\", \"instrument\", \"agent\", \"artifacct/person\"],\n",
    "    \"transaction.transfermoney\":[\"giver\",\"recipient\", \"money\"],\n",
    "    \"conflict.attack\":[\"attacker\", \"instrument\", \"place\", \"target\"],\n",
    "    \"conflict.demonstrate\":[\"demonstrator\", \"instrument\", \"police\", \"place\"],\n",
    "    \"contact.meet\":[\"participant\", \"place\"],\n",
    "    \"contact.phone-write\":[\"participant\", \"instrument\", \"place\"],\n",
    "    \"justice.arrestjail\":[\"agent\", \"person\", \"instrument\", \"place\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b78097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article text length: 1205 characters\n",
      "Base folder: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\n",
      "Article copied to: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\articles\\VOA_EN_NW_2009.12.09.416313.rsd.txt\n",
      "Images copied: 3 into c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\images\n",
      "Empty JSON created at: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\OUTPUT_VOA_EN_NW_2009.12.09.416313.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# 1) Set the article filename here (must exist under m2e2_rawdata/article)\n",
    "article_filename = \"VOA_EN_NW_2009.12.09.416313.rsd.txt\"  # change this\n",
    "\n",
    "# 2) Option: change matching behavior if needed\n",
    "strict_prefix_match = True  # if False, will also match images that merely contain the base name\n",
    "\n",
    "# --- Paths ---\n",
    "project_root = Path.cwd()\n",
    "article_dir = project_root / \"m2e2_rawdata\" / \"article\"\n",
    "images_dir = project_root / \"m2e2_rawdata\" / \"image\" / \"image\"\n",
    "\n",
    "# Validate paths\n",
    "article_path = article_dir / article_filename\n",
    "if not article_path.exists():\n",
    "    raise FileNotFoundError(f\"Article file not found: {article_path}\")\n",
    "if not images_dir.exists():\n",
    "    raise FileNotFoundError(f\"Images directory not found: {images_dir}\")\n",
    "\n",
    "# Read the article text into a variable\n",
    "article_text = article_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "# Derive a base name by stripping .txt and optional .rsd suffix\n",
    "base_name = article_filename\n",
    "if base_name.endswith(\".txt\"):\n",
    "    base_name = base_name[:-4]\n",
    "if base_name.endswith(\".rsd\"):\n",
    "    base_name = base_name[:-4]\n",
    "\n",
    "\n",
    "output_root = project_root / \"output\"\n",
    "base_output_dir = output_root / base_name\n",
    "articles_output_dir = base_output_dir / \"articles\"\n",
    "images_output_dir = base_output_dir / \"images\"\n",
    "articles_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "images_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy the article file into articles subfolder\n",
    "shutil.copy2(article_path, articles_output_dir / article_filename)\n",
    "\n",
    "# Find corresponding images\n",
    "matched_images = []\n",
    "for img_path in images_dir.glob(\"*.jpg\"):\n",
    "    name = img_path.name\n",
    "    if strict_prefix_match:\n",
    "        if name.startswith(base_name):\n",
    "            matched_images.append(img_path)\n",
    "    else:\n",
    "        if base_name in name:\n",
    "            matched_images.append(img_path)\n",
    "\n",
    "# Copy images into the images subfolder\n",
    "for img in matched_images:\n",
    "    shutil.copy2(img, images_output_dir / img.name)\n",
    "\n",
    "# Create an empty JSON file at the base folder level\n",
    "json_path = base_output_dir / f\"OUTPUT_{base_name}.json\"\n",
    "json_path.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Article text length: {len(article_text)} characters\")\n",
    "print(f\"Base folder: {base_output_dir}\")\n",
    "print(f\"Article copied to: {articles_output_dir / article_filename}\")\n",
    "print(f\"Images copied: {len(matched_images)} into {images_output_dir}\")\n",
    "print(f\"Empty JSON created at: {json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac5451",
   "metadata": {},
   "source": [
    "## (i) Text-only extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4da8cb",
   "metadata": {},
   "source": [
    "In WASE, each sentence is paired with the most relevant image (via embedding similarity). Right now we are choosing to not do that but in future we will: Either ask the LLM to select which image best matches a sentence (if you can pass both text + images together), or compute a similarity score (text embedding vs image embedding) and pick the closest image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a41f1",
   "metadata": {},
   "source": [
    "TO-DO: Pass images in input and ask prompt to select images that best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75db451",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_json = [\n",
    "    {\n",
    "        \"sentence_id\": 1,\n",
    "        \"text\": \"UNECA Director Says Dangers in Guinea are Serious\",\n",
    "        \"events\": [\n",
    "            {\n",
    "                \"event_type\": \"Conflict.Attack\",\n",
    "                \"modality\": \"text\",\n",
    "                \"trigger\": {\"text\": \"Dangers\", \"char_start\": 22, \"char_end\": 28},\n",
    "                \"arguments\": [\n",
    "                    {\"role\": \"Place\", \"text\": \"Guinea\", \"char_start\": 32, \"char_end\": 37}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"sentence_id\": 2,\n",
    "        \"text\": \"Bodies of people killed during a rally are seen at the capital's main mosque in Conakry, Guinea\",\n",
    "        \"events\": [\n",
    "            {\n",
    "                \"event_type\": \"Conflict.Attack\",\n",
    "                \"modality\": \"text\",\n",
    "                \"trigger\": {\"text\": \"killed\", \"char_start\": 20, \"char_end\": 26},\n",
    "                \"arguments\": [\n",
    "                    {\"role\": \"Victim\", \"text\": \"people\", \"char_start\": 10, \"char_end\": 16},\n",
    "                    {\"role\": \"Place\", \"text\": \"Conakry, Guinea\", \"char_start\": 82, \"char_end\": 96}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cca6f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "\n",
    "model_name = \"google/gemma-3-1b-it\"  # smaller version (270m) - performance was not good at all\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\")\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "you are an information extraction system. Extract events and arguments for each sentence from the following article: {article_text}.\n",
    "\n",
    "RULES:\n",
    "1. Only use the following event types and their argument roles: {event_arg}\n",
    "2. Output **must be a valid JSON array** only, nothing else. **Do not add markdown, backslashes, escape characters, or extra text**.\n",
    "3. Only use double quotation marks (\") for JSON strings.\n",
    "4. Each event must include:\n",
    "    a. \"sentence id\": an iterator over all the sentences\n",
    "    b. \"text\": the sentence itself\n",
    "    c. \"events\": these further contain the following:\n",
    "        a. \"event_type\": the event type string.\n",
    "        b. \"modality\": always text.\n",
    "        c. \"trigger\": the word(S) that signal the event, with \"text\", \"char_start\", \"char_end\".\n",
    "        d. \"arguments\": a list of objects, each with:\n",
    "            i. \"role\": role from the ontology.\n",
    "            ii. \"text\" the argument string.\n",
    "            iii. \"char_start\": start character index of the argument string.\n",
    "            iv. \"char_end\": end character index of the argument string.\n",
    "5. Offsets are character indices in the sentence (0-based, inclusive-exclusive).\n",
    "6. **Do not include explanations, notes, comments, or any text outside the JSON array.**\n",
    "7. The output must be fully parseable by `json.loads()` in Python.\n",
    "\n",
    "\n",
    "Here is an example output, your output should follow this exact JSON format, there can be more or less sentence id depending on the article: {example_json}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output_ids = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=1024,  # adjust based on expected length\n",
    "    do_sample=False  # deterministic output\n",
    ")\n",
    "\n",
    "#generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "generated_ids = output_ids[0][inputs['input_ids'].shape[1]:]\n",
    "generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1719ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n[\\n  {\\'sentence_id\\': 1, \\'text\\': \\'UNECA Director Says Dangers in Guinea are Serious\\', \\'events\\': [{\\'event_type\\': \\'Conflict.Attack\\', \\'modality\\': \\'text\\', \\'trigger\\': {\\'text\\': \\'Dangers\\', \\'char_start\\': 22, \\'char_end\\': 28}, \\'arguments\\': [{\\'role\\': \\'Place\\', \\'text\\': \\'Guinea\\', \\'char_start\\': 32, \\'char_end\\': 37}]}]},\\n  {\\'sentence_id\\': 2, \\'text\\': \"Bodies of people killed during a rally are seen at the capital\\'s main mosque in Conakry, Guinea\", \\'events\\': [{\\'event_type\\': \\'Conflict.Attack\\', \\'modality\\': \\'text\\', \\'trigger\\': {\\'text\\': \\'killed\\', \\'char_start\\': 20, \\'char_end\\': 26}, \\'arguments\\': [{\\'role\\': \\'Victim\\', \\'text\\': \\'people\\', \\'char_start\\': 10, \\'char_end\\': 16}, {\\'role\\': \\'Place\\', \\'text\\': \\'Conakry, Guinea\\', \\'char_start\\': 82, \\'char_end\\': 96}]}]}\\n]\\n```\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe5774b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"sentence_id\": 1,\n",
      "    \"text\": \"UNECA Director Says Dangers in Guinea are Serious\",\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_type\": \"Conflict.Attack\",\n",
      "        \"modality\": \"text\",\n",
      "        \"trigger\": {\n",
      "          \"text\": \"Dangers\",\n",
      "          \"char_start\": 22,\n",
      "          \"char_end\": 28\n",
      "        },\n",
      "        \"arguments\": [\n",
      "          {\n",
      "            \"role\": \"Place\",\n",
      "            \"text\": \"Guinea\",\n",
      "            \"char_start\": 32,\n",
      "            \"char_end\": 37\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"sentence_id\": 2,\n",
      "    \"text\": \"Bodies of people killed during a rally are seen at the capital's main mosque in Conakry, Guinea\",\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_type\": \"Conflict.Attack\",\n",
      "        \"modality\": \"text\",\n",
      "        \"trigger\": {\n",
      "          \"text\": \"killed\",\n",
      "          \"char_start\": 20,\n",
      "          \"char_end\": 26\n",
      "        },\n",
      "        \"arguments\": [\n",
      "          {\n",
      "            \"role\": \"Victim\",\n",
      "            \"text\": \"people\",\n",
      "            \"char_start\": 10,\n",
      "            \"char_end\": 16\n",
      "          },\n",
      "          {\n",
      "            \"role\": \"Place\",\n",
      "            \"text\": \"Conakry, Guinea\",\n",
      "            \"char_start\": 82,\n",
      "            \"char_end\": 96\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "cleaned_text = generated_text.strip('```json\\n').strip('```\\n')\n",
    "\n",
    "python_obj = ast.literal_eval(cleaned_text)\n",
    "\n",
    "json_data = json.dumps(python_obj, indent=2)\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d45ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\OUTPUT_VOA_EN_NW_2009.12.09.416313.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    out_path = json_path  # from earlier cell\n",
    "except NameError:\n",
    "    project_root = Path.cwd()\n",
    "    base_output_dir = project_root / \"output\" / base_name\n",
    "    base_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = base_output_dir / f\"OUTPUT_{base_name}.json\"\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(json_data)\n",
    "\n",
    "print(f\"Saved JSON to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf4d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fca2419",
   "metadata": {},
   "source": [
    "## (ii) Image-only extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6689b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_json_img = [\n",
    "  {\n",
    "    \"image_id\": \"Actual_Image_Name.jpg\",\n",
    "    \"events\": [\n",
    "      {\n",
    "        \"event_type\": \"Conflict.Attack\",\n",
    "        \"modality\": \"image\",\n",
    "        \"trigger\": {\"text\": \"attack\"}, \n",
    "        \"arguments\": [\n",
    "          {\n",
    "            \"role\": \"Attacker\",\n",
    "            \"text\": \"soldiers\",\n",
    "            \"bbox\": [0.12, 0.40, 0.45, 0.78]\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"Victim\",\n",
    "            \"text\": \"protesters\",\n",
    "            \"bbox\": [0.50, 0.35, 0.80, 0.70]\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"Place\",\n",
    "            \"text\": \"Conakry\",\n",
    "            \"bbox\": [0.05, 0.10, 0.30, 0.25]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fb1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f27c5c82d14512834b24cb2f7fa0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "model_name = \"google/gemma-3-4b-it\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"cpu\", offload_folder=\"offload\")\n",
    "\n",
    "\n",
    "\n",
    "# Example: load one image\n",
    "img_path = images_output_dir / matched_images[2].name  # from earlier matching\n",
    "#img_path = \"output\\VOA_EN_NW_2009.12.09.416313\\images\\VOA_EN_NW_2009.12.09.416313_0.jpg\"\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "<start_of_image><end_of_image>\n",
    "\n",
    "You are an event extraction system. Analyze the image called {matched_images[2].name} and extract events.\n",
    "\n",
    "RULES:\n",
    "1. Only use the following event types and their roles: {event_arg}\n",
    "2. Output **must be a valid JSON array** only, nothing else. **Do not add markdown, backslashes, escape characters, or extra text**.\n",
    "3. Each event must include:\n",
    "   - \"event_type\": the event type.\n",
    "   - \"modality\": always \"image\".\n",
    "   - \"trigger\": a short word/phrase describing the main event (string only).\n",
    "   - \"arguments\": a list of objects, each with:\n",
    "       * \"role\": role name\n",
    "       * \"text\": short phrase for the entity (e.g., \"soldier\", \"protesters\", \"gun\", \"car\").\n",
    "       * \"bbox\": [x_min, y_min, x_max, y_max] with normalized coordinates between 0 and 1.\n",
    "4. If no clear event is present, return an empty list [].\n",
    "5. Do not add notes, markdown, or comments â€” only strict JSON.\n",
    "\n",
    "\n",
    "here is an example \n",
    "\n",
    "Here is an example output, your output should follow this exact JSON format: {example_json_img}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "inputs = processor(text=prompt, images=[image], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate\n",
    "generated_ids = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c150087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'boi_token': '<start_of_image>', 'eoi_token': '<end_of_image>', 'image_token': '<image_soft_token>'}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(processor.tokenizer.special_tokens_map)\n",
    "print(processor.tokenizer.additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18605332",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "generated_text = processor.batch_decode(generated_ids[:, input_length:], skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22c280f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n[\\n  {\\n    \"image_id\": \"VOA_EN_NW_2009.12.09.416313_0.jpg\",\\n    \"events\": [\\n      {\\n        \"event_type\": \"Conflict.Attack\",\\n        \"modality\": \"image\",\\n        \"trigger\": {\\n          \"text\": \"soldiers\"\\n        },\\n        \"arguments\": [\\n          {\\n            \"role\": \"attacker\",\\n            \"text\": \"soldiers\",\\n            \"bbox\": [\\n              0.12,\\n              0.4,\\n              0.45,\\n              0.78\\n            ]\\n          },\\n          {\\n            \"role\": \"target\",\\n            \"text\": \"protesters\",\\n            \"bbox\": [\\n              0.5,\\n              0.35,\\n              0.8,\\n              0.7\\n            ]\\n          }\\n        ]\\n      }\\n    ]\\n  }\\n]\\n```'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40755465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"image_id\": \"VOA_EN_NW_2009.12.09.416313_0.jpg\",\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_type\": \"Conflict.Attack\",\n",
      "        \"modality\": \"image\",\n",
      "        \"trigger\": {\n",
      "          \"text\": \"soldiers\"\n",
      "        },\n",
      "        \"arguments\": [\n",
      "          {\n",
      "            \"role\": \"attacker\",\n",
      "            \"text\": \"soldiers\",\n",
      "            \"bbox\": [\n",
      "              0.12,\n",
      "              0.4,\n",
      "              0.45,\n",
      "              0.78\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"role\": \"target\",\n",
      "            \"text\": \"protesters\",\n",
      "            \"bbox\": [\n",
      "              0.5,\n",
      "              0.35,\n",
      "              0.8,\n",
      "              0.7\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "cleaned_text = generated_text.strip('```json\\n').strip('```\\n')\n",
    "\n",
    "python_obj = ast.literal_eval(cleaned_text)\n",
    "\n",
    "json_data = json.dumps(python_obj, indent=2)\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd876105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended JSON to: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\OUTPUT_VOA_EN_NW_2009.12.09.416313.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    out_path = json_path  # from earlier cell\n",
    "except NameError:\n",
    "    project_root = Path.cwd()\n",
    "    base_output_dir = project_root / \"output\" / base_name\n",
    "    base_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = base_output_dir / f\"OUTPUT_{base_name}.json\"\n",
    "\n",
    "# Load existing JSON if file exists, otherwise start with an empty list\n",
    "if out_path.exists():\n",
    "    with open(out_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        existing_data = json.load(f)\n",
    "else:\n",
    "    existing_data = []\n",
    "\n",
    "# Assume json_data is a dict (or list of dicts) that you want to add\n",
    "new_data = json.loads(json_data)  # convert string to Python object\n",
    "if isinstance(new_data, list):\n",
    "    existing_data.extend(new_data)\n",
    "else:\n",
    "    existing_data.append(new_data)\n",
    "\n",
    "# Save back to file\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(existing_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Appended JSON to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc16c5",
   "metadata": {},
   "source": [
    "## (iii) Cross-media alignment Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7817f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd28579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
