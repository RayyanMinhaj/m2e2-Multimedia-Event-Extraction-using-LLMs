{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8dbbe6",
   "metadata": {},
   "source": [
    "# Reproducing M2E2 using a prompt-based LLM\n",
    "DFKI | Rayyan M."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2736b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d58748a",
   "metadata": {},
   "source": [
    "### Defining schema/ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b573b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event obj : argument roles from M2E2 dataset paper\n",
    "\n",
    "event_arg = {\n",
    "    \"life.die\":[\"agent\", \"victim\", \"instrument\", \"place\"],\n",
    "    \"movement.transport\":[\"destination\", \"origin\", \"instrument\", \"agent\", \"artifacct/person\"],\n",
    "    \"transaction.transfermoney\":[\"giver\",\"recipient\", \"money\"],\n",
    "    \"conflict.attack\":[\"attacker\", \"instrument\", \"place\", \"target\"],\n",
    "    \"conflict.demonstrate\":[\"demonstrator\", \"instrument\", \"police\", \"place\"],\n",
    "    \"contact.meet\":[\"participant\", \"place\"],\n",
    "    \"contact.phone-write\":[\"participant\", \"instrument\", \"place\"],\n",
    "    \"justice.arrestjail\":[\"agent\", \"person\", \"instrument\", \"place\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b78097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article text length: 1205 characters\n",
      "Base folder: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\n",
      "Article copied to: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\articles\\VOA_EN_NW_2009.12.09.416313.rsd.txt\n",
      "Images copied: 3 into c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\images\n",
      "Empty JSON created at: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\OUTPUT_VOA_EN_NW_2009.12.09.416313.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# 1) Set the article filename here (must exist under m2e2_rawdata/article)\n",
    "article_filename = \"VOA_EN_NW_2009.12.09.416313.rsd.txt\"  # change this\n",
    "\n",
    "# 2) Option: change matching behavior if needed\n",
    "strict_prefix_match = True  # if False, will also match images that merely contain the base name\n",
    "\n",
    "# --- Paths ---\n",
    "project_root = Path.cwd()\n",
    "article_dir = project_root / \"m2e2_rawdata\" / \"article\"\n",
    "images_dir = project_root / \"m2e2_rawdata\" / \"image\" / \"image\"\n",
    "\n",
    "# Validate paths\n",
    "article_path = article_dir / article_filename\n",
    "if not article_path.exists():\n",
    "    raise FileNotFoundError(f\"Article file not found: {article_path}\")\n",
    "if not images_dir.exists():\n",
    "    raise FileNotFoundError(f\"Images directory not found: {images_dir}\")\n",
    "\n",
    "# Read the article text into a variable\n",
    "article_text = article_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "# Derive a base name by stripping .txt and optional .rsd suffix\n",
    "base_name = article_filename\n",
    "if base_name.endswith(\".txt\"):\n",
    "    base_name = base_name[:-4]\n",
    "if base_name.endswith(\".rsd\"):\n",
    "    base_name = base_name[:-4]\n",
    "\n",
    "\n",
    "output_root = project_root / \"output\"\n",
    "base_output_dir = output_root / base_name\n",
    "articles_output_dir = base_output_dir / \"articles\"\n",
    "images_output_dir = base_output_dir / \"images\"\n",
    "articles_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "images_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy the article file into articles subfolder\n",
    "shutil.copy2(article_path, articles_output_dir / article_filename)\n",
    "\n",
    "# Find corresponding images\n",
    "matched_images = []\n",
    "for img_path in images_dir.glob(\"*.jpg\"):\n",
    "    name = img_path.name\n",
    "    if strict_prefix_match:\n",
    "        if name.startswith(base_name):\n",
    "            matched_images.append(img_path)\n",
    "    else:\n",
    "        if base_name in name:\n",
    "            matched_images.append(img_path)\n",
    "\n",
    "# Copy images into the images subfolder\n",
    "for img in matched_images:\n",
    "    shutil.copy2(img, images_output_dir / img.name)\n",
    "\n",
    "# Create an empty JSON file at the base folder level\n",
    "json_path = base_output_dir / f\"OUTPUT_{base_name}.json\"\n",
    "json_path.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Article text length: {len(article_text)} characters\")\n",
    "print(f\"Base folder: {base_output_dir}\")\n",
    "print(f\"Article copied to: {articles_output_dir / article_filename}\")\n",
    "print(f\"Images copied: {len(matched_images)} into {images_output_dir}\")\n",
    "print(f\"Empty JSON created at: {json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac5451",
   "metadata": {},
   "source": [
    "## (i) Text-only extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75db451",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_json = [\n",
    "    {\n",
    "        \"sentence_id\": 1,\n",
    "        \"text\": \"UNECA Director Says Dangers in Guinea are Serious\",\n",
    "        \"events\": [\n",
    "            {\n",
    "                \"event_type\": \"Conflict.Attack\",\n",
    "                \"modality\": \"text\",\n",
    "                \"trigger\": {\"text\": \"Dangers\", \"char_start\": 22, \"char_end\": 28},\n",
    "                \"arguments\": [\n",
    "                    {\"role\": \"Place\", \"text\": \"Guinea\", \"char_start\": 32, \"char_end\": 37}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"sentence_id\": 2,\n",
    "        \"text\": \"Bodies of people killed during a rally are seen at the capital's main mosque in Conakry, Guinea\",\n",
    "        \"events\": [\n",
    "            {\n",
    "                \"event_type\": \"Conflict.Attack\",\n",
    "                \"modality\": \"text\",\n",
    "                \"trigger\": {\"text\": \"killed\", \"char_start\": 20, \"char_end\": 26},\n",
    "                \"arguments\": [\n",
    "                    {\"role\": \"Victim\", \"text\": \"people\", \"char_start\": 10, \"char_end\": 16},\n",
    "                    {\"role\": \"Place\", \"text\": \"Conakry, Guinea\", \"char_start\": 82, \"char_end\": 96}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6cca6f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "\n",
    "model_name = \"google/gemma-3-1b-it\"  # smaller version - performance was not good at all\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\")\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "you are an information extraction system. Extract events and arguments for each sentence from the following article: {article_text}.\n",
    "\n",
    "RULES:\n",
    "1. Only use the following event types and their argument roles: {event_arg}\n",
    "2. Output **must be a valid JSON array** only, nothing else. **Do not add markdown, backslashes, escape characters, or extra text**.\n",
    "3. Only use double quotation marks (\") for JSON strings.\n",
    "4. Each event must include:\n",
    "    a. \"sentence id\": an iterator over all the sentences\n",
    "    b. \"text\": the sentence itself\n",
    "    c. \"events\": these further contain the following:\n",
    "        a. \"event_type\": the event type string.\n",
    "        b. \"modality\": always text.\n",
    "        c. \"trigger\": the word(S) that signal the event, with \"text\", \"char_start\", \"char_end\".\n",
    "        d. \"arguments\": a list of objects, each with:\n",
    "            i. \"role\": role from the ontology.\n",
    "            ii. \"text\" the argument string.\n",
    "            iii. \"char_start\": start character index of the argument string.\n",
    "            iv. \"char_end\": end character index of the argument string.\n",
    "5. Offsets are character indices in the sentence (0-based, inclusive-exclusive).\n",
    "6. **Do not include explanations, notes, comments, or any text outside the JSON array.**\n",
    "7. The output must be fully parseable by `json.loads()` in Python.\n",
    "\n",
    "\n",
    "Here is an example output, your output should follow this exact JSON format, there can be more or less sentence id depending on the article: {example_json}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output_ids = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=1024,  # adjust based on expected length\n",
    "    do_sample=False  # deterministic output\n",
    ")\n",
    "\n",
    "#generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "generated_ids = output_ids[0][inputs['input_ids'].shape[1]:]\n",
    "generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800721d7",
   "metadata": {},
   "source": [
    "Converting output into json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe5774b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"sentence_id\": 1,\n",
      "    \"text\": \"UNECA Director Says Dangers in Guinea are Serious\",\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_type\": \"Conflict.Attack\",\n",
      "        \"modality\": \"text\",\n",
      "        \"trigger\": {\n",
      "          \"text\": \"Dangers\",\n",
      "          \"char_start\": 22,\n",
      "          \"char_end\": 28\n",
      "        },\n",
      "        \"arguments\": [\n",
      "          {\n",
      "            \"role\": \"Place\",\n",
      "            \"text\": \"Guinea\",\n",
      "            \"char_start\": 32,\n",
      "            \"char_end\": 37\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"sentence_id\": 2,\n",
      "    \"text\": \"Bodies of people killed during a rally are seen at the capital's main mosque in Conakry, Guinea\",\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_type\": \"Conflict.Attack\",\n",
      "        \"modality\": \"text\",\n",
      "        \"trigger\": {\n",
      "          \"text\": \"killed\",\n",
      "          \"char_start\": 20,\n",
      "          \"char_end\": 26\n",
      "        },\n",
      "        \"arguments\": [\n",
      "          {\n",
      "            \"role\": \"Victim\",\n",
      "            \"text\": \"people\",\n",
      "            \"char_start\": 10,\n",
      "            \"char_end\": 16\n",
      "          },\n",
      "          {\n",
      "            \"role\": \"Place\",\n",
      "            \"text\": \"Conakry, Guinea\",\n",
      "            \"char_start\": 82,\n",
      "            \"char_end\": 96\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "cleaned_text = generated_text.strip('```json\\n').strip('```\\n')\n",
    "\n",
    "# Safely evaluate the Python literal into Python objects\n",
    "python_obj = ast.literal_eval(cleaned_text)\n",
    "\n",
    "# Convert to proper JSON\n",
    "json_data = json.dumps(python_obj, indent=2)\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d45ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: c:\\Users\\rayya\\Desktop\\DFKI\\M2E2\\output\\VOA_EN_NW_2009.12.09.416313\\OUTPUT_VOA_EN_NW_2009.12.09.416313.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    out_path = json_path  # from earlier cell\n",
    "except NameError:\n",
    "    project_root = Path.cwd()\n",
    "    base_output_dir = project_root / \"output\" / base_name\n",
    "    base_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = base_output_dir / f\"OUTPUT_{base_name}.json\"\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(json_data)\n",
    "\n",
    "print(f\"Saved JSON to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf4d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fca2419",
   "metadata": {},
   "source": [
    "## (ii) Image-only extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc16c5",
   "metadata": {},
   "source": [
    "## (iii) Cross-media alignment Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7817f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd28579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
